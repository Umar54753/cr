{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**code number1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 11797, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 17538.921166\n",
      "\n",
      "ğŸ”¹ Model: XGBoost\n",
      "âœ… MAE: 49.25\n",
      "âœ… MSE: 6867.48\n",
      "âœ… RMSE: 82.87\n",
      "âœ… RÂ² Score: 0.99982\n",
      "\n",
      "ğŸ”¹ Model: LightGBM\n",
      "âœ… MAE: 53.27\n",
      "âœ… MSE: 15655.69\n",
      "âœ… RMSE: 125.12\n",
      "âœ… RÂ² Score: 0.99959\n",
      "\n",
      "âœ… Models saved successfully as 'best_xgb_model.pkl' and 'best_lgbm_model.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib  # For saving the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the cleaned dataset\n",
    "file_path = \"cleaned_car_dataset.csv\"  # Change this to your dataset path\n",
    "df_cleaned = pd.read_csv(file_path)\n",
    "\n",
    "# Split features (X) and target (y)\n",
    "X = df_cleaned.drop(columns=[\"price\"])\n",
    "y = df_cleaned[\"price\"]\n",
    "\n",
    "# Encode categorical columns\n",
    "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define best models with tuned parameters\n",
    "best_xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6)\n",
    "best_lgbm = LGBMRegressor(n_estimators=200, learning_rate=0.1, num_leaves=100)\n",
    "\n",
    "# Train models\n",
    "best_xgb.fit(X_train_scaled, y_train)\n",
    "best_lgbm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = best_xgb.predict(X_test_scaled)\n",
    "y_pred_lgbm = best_lgbm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate_model(y_test, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"\\nğŸ”¹ Model: {model_name}\")\n",
    "    print(f\"âœ… MAE: {mae:.2f}\")\n",
    "    print(f\"âœ… MSE: {mse:.2f}\")\n",
    "    print(f\"âœ… RMSE: {rmse:.2f}\")\n",
    "    print(f\"âœ… RÂ² Score: {r2:.5f}\")\n",
    "\n",
    "evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n",
    "evaluate_model(y_test, y_pred_lgbm, \"LightGBM\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_xgb, \"best_xgb_model.pkl\")\n",
    "joblib.dump(best_lgbm, \"best_lgbm_model.pkl\")\n",
    "print(\"\\nâœ… Models saved successfully as 'best_xgb_model.pkl' and 'best_lgbm_model.pkl'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 11797, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 17538.921166\n",
      "âœ… Models, encoders, and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#save scaller\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"cleaned_car_dataset.csv\"\n",
    "df_cleaned = pd.read_csv(file_path)\n",
    "\n",
    "# Split features and target\n",
    "X = df_cleaned.drop(columns=[\"price\"])\n",
    "y = df_cleaned[\"price\"]\n",
    "\n",
    "# Encode categorical columns and save encoders\n",
    "encoders = {}\n",
    "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    encoders[col] = le  # Store the encoder\n",
    "\n",
    "# Save encoders\n",
    "joblib.dump(encoders, \"label_encoders.pkl\")\n",
    "\n",
    "# Normalize numerical features and save scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models\n",
    "best_xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6)\n",
    "best_lgbm = LGBMRegressor(n_estimators=200, learning_rate=0.1, num_leaves=100)\n",
    "\n",
    "best_xgb.fit(X_train, y_train)\n",
    "best_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Save trained models\n",
    "joblib.dump(best_xgb, \"best_xgb_model.pkl\")\n",
    "joblib.dump(best_lgbm, \"best_lgbm_model.pkl\")\n",
    "\n",
    "print(\"âœ… Models, encoders, and scaler saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction script ready to use!\n"
     ]
    }
   ],
   "source": [
    "#save encoder\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved models\n",
    "best_xgb = joblib.load(\"best_xgb_model.pkl\")\n",
    "best_lgbm = joblib.load(\"best_lgbm_model.pkl\")\n",
    "\n",
    "# Load preprocessing objects\n",
    "encoders = joblib.load(\"label_encoders.pkl\")  # Load saved LabelEncoders\n",
    "scaler = joblib.load(\"scaler.pkl\")  # Load saved StandardScaler\n",
    "\n",
    "def preprocess_user_input(user_input):\n",
    "    \"\"\"Preprocess user input to match the trained model format.\"\"\"\n",
    "    user_df = pd.DataFrame([user_input])\n",
    "\n",
    "    # Encode categorical columns using saved encoders\n",
    "    categorical_cols = [\"make_model\", \"body_type\", \"Type\", \"Fuel\", \"Gearing_Type\", \"Drive_chain\", \"Paint_Type\", \"Upholstery_type\"]\n",
    "    for col in categorical_cols:\n",
    "        if col in user_df.columns and col in encoders:\n",
    "            user_df[col] = encoders[col].transform(user_df[col])\n",
    "\n",
    "    # Scale numerical features using saved scaler\n",
    "    numerical_cols = [\"km\", \"age\", \"Previous_Owners\", \"hp_kW\", \"Displacement_cc\", \"Weight_kg\", \"cons_comb\"]\n",
    "    user_df[numerical_cols] = scaler.transform(user_df[numerical_cols])\n",
    "\n",
    "    return user_df\n",
    "\n",
    "def predict_price(user_input):\n",
    "    \"\"\"Predicts car price based on user input.\"\"\"\n",
    "    user_df = preprocess_user_input(user_input)\n",
    "    predicted_price = best_xgb.predict(user_df)\n",
    "    return predicted_price[0]\n",
    "\n",
    "print(\"âœ… Prediction script ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš— **Car Recommendation System** ğŸš—\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#script3\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load trained models\n",
    "best_xgb = joblib.load(\"best_xgb_model.pkl\")\n",
    "\n",
    "# Load preprocessing objects (LabelEncoders & Scaler)\n",
    "encoders = joblib.load(\"label_encoders.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv(\"cleaned_car_dataset.csv\")\n",
    "\n",
    "# Expected columns\n",
    "expected_numerical_cols = [\n",
    "    \"km\", \"age\", \"Previous_Owners\", \"hp_kW\", \"Displacement_cc\", \n",
    "    \"Weight_kg\", \"cons_comb\", \"estimated_resale_price\", \"price_per_km\", \"age_mileage_score\"\n",
    "]\n",
    "expected_categorical_cols = [\n",
    "    \"make_model\", \"body_type\", \"Type\", \"Fuel\", \"Gearing_Type\", \n",
    "    \"Drive_chain\", \"Paint_Type\", \"Upholstery_type\"\n",
    "]\n",
    "\n",
    "# Hints for user input\n",
    "car_models = [\"Audi A1\", \"Audi A2\", \"Audi A3\", \"Opel Astra\", \"Opel Corsa\", \"Opel Insignia\",\n",
    "              \"Renault Clio\", \"Renault Duster\", \"Renault Espace\"]\n",
    "fuel_types = [\"Diesel\", \"Benzine\", \"LPG/CNG\", \"Electric\"]\n",
    "body_types = [\"Sedans\", \"Station wagon\", \"Compact\", \"Coupe\", \"Van\", \"Off-Road\", \"Convertible\", \"Transporter\"]\n",
    "\n",
    "def preprocess_user_input(user_input):\n",
    "    \"\"\"Preprocess user input to match trained model format.\"\"\"\n",
    "    user_df = pd.DataFrame([user_input])\n",
    "\n",
    "    # Ensure missing numerical columns are filled with default values (0)\n",
    "    for col in expected_numerical_cols:\n",
    "        if col not in user_df:\n",
    "            user_df[col] = 0  \n",
    "\n",
    "    # Ensure missing categorical columns are filled with \"Unknown\"\n",
    "    for col in expected_categorical_cols:\n",
    "        if col not in user_df:\n",
    "            user_df[col] = \"Unknown\"\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    user_df = user_df[expected_numerical_cols + expected_categorical_cols]\n",
    "\n",
    "    # Encode categorical columns\n",
    "    for col in expected_categorical_cols:\n",
    "        if col in encoders:\n",
    "            le = encoders[col]\n",
    "            known_labels = set(le.classes_)\n",
    "            user_df[col] = user_df[col].apply(lambda x: le.transform([x])[0] if x in known_labels else -1)\n",
    "\n",
    "    # Convert categorical columns to numeric\n",
    "    user_df[expected_categorical_cols] = user_df[expected_categorical_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Fill NaN values\n",
    "    user_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Ensure numerical columns match the scaler\n",
    "    user_df[scaler.feature_names_in_] = scaler.transform(user_df[scaler.feature_names_in_])\n",
    "\n",
    "    return user_df\n",
    "\n",
    "def predict_price(user_input):\n",
    "    \"\"\"Predicts the price of a car based on user specifications.\"\"\"\n",
    "    user_df = preprocess_user_input(user_input)\n",
    "    predicted_price = best_xgb.predict(user_df)\n",
    "    return predicted_price[0]\n",
    "\n",
    "def recommend_cars(user_input, dataset):\n",
    "    \"\"\"Recommends cars based on user preferences.\"\"\"\n",
    "    \n",
    "    # Flexible filtering\n",
    "    filtered_cars = dataset[\n",
    "        (dataset[\"make_model\"] == user_input.get(\"make_model\", dataset[\"make_model\"])) &\n",
    "        (dataset[\"km\"] >= user_input.get(\"min_mileage\", 0)) &\n",
    "        (dataset[\"km\"] <= user_input.get(\"max_mileage\", float('inf'))) &\n",
    "        (dataset[\"price\"] <= user_input.get(\"budget\", float('inf'))) &\n",
    "        (dataset[\"Fuel\"] == user_input.get(\"Fuel\", dataset[\"Fuel\"])) &\n",
    "        (dataset[\"body_type\"] == user_input.get(\"body_type\", dataset[\"body_type\"]))\n",
    "    ]\n",
    "    \n",
    "    # Sort by estimated resale value\n",
    "    filtered_cars = filtered_cars.sort_values(by=\"estimated_resale_price\", ascending=False)\n",
    "\n",
    "    # Alternative suggestions if no exact match\n",
    "    if filtered_cars.empty:\n",
    "        alternative_cars = dataset[\n",
    "            (dataset[\"price\"] <= user_input.get(\"budget\", float('inf')) * 1.2) &  # Budget flexibility\n",
    "            (dataset[\"km\"] <= user_input.get(\"max_mileage\", float('inf')) * 1.3)  # Allow higher mileage\n",
    "        ].sort_values(by=\"estimated_resale_price\", ascending=False).head(5)\n",
    "        return alternative_cars\n",
    "\n",
    "    return filtered_cars.head(5)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the car recommendation system.\"\"\"\n",
    "    dataset = pd.read_csv(\"cleaned_car_dataset.csv\")\n",
    "\n",
    "    print(\"\\n **Car Recommendation System** \\n\")\n",
    "    \n",
    "    user_input = {\n",
    "        \"make_model\": input(f\"Enter car model (e.g., {', '.join(car_models[:3])}, ...): \"),\n",
    "        \"min_mileage\": float(input(\"Enter min mileage (e.g., 20000): \") or 0),\n",
    "        \"max_mileage\": float(input(\"Enter max mileage (e.g., 60000): \") or float('inf')),\n",
    "        \"budget\": float(input(\"Enter budget (e.g., 25000): \") or float('inf')),\n",
    "        \"Fuel\": input(f\"Enter fuel type ({', '.join(fuel_types)}): \"),\n",
    "        \"body_type\": input(f\"Enter body type ({', '.join(body_types)}): \")\n",
    "    }\n",
    "\n",
    "    # Get recommendations\n",
    "    recommendations = recommend_cars(user_input, dataset)\n",
    "\n",
    "    if not recommendations.empty:\n",
    "        print(\"\\n **Recommended Cars:**\")\n",
    "        print(recommendations[[\"make_model\", \"km\", \"price\", \"estimated_resale_price\"]])\n",
    "    else:\n",
    "        print(\"\\n No cars found matching your criteria. Try adjusting your preferences.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
