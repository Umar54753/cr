{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**code number1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 11797, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 17538.921166\n",
      "\n",
      "ğŸ”¹ Model: XGBoost\n",
      "âœ… MAE: 49.25\n",
      "âœ… MSE: 6867.48\n",
      "âœ… RMSE: 82.87\n",
      "âœ… RÂ² Score: 0.99982\n",
      "\n",
      "ğŸ”¹ Model: LightGBM\n",
      "âœ… MAE: 53.27\n",
      "âœ… MSE: 15655.69\n",
      "âœ… RMSE: 125.12\n",
      "âœ… RÂ² Score: 0.99959\n",
      "\n",
      "âœ… Models saved successfully as 'best_xgb_model.pkl' and 'best_lgbm_model.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib  # For saving the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the cleaned dataset\n",
    "file_path = \"cleaned_car_dataset.csv\"  # Change this to your dataset path\n",
    "df_cleaned = pd.read_csv(file_path)\n",
    "\n",
    "# Split features (X) and target (y)\n",
    "X = df_cleaned.drop(columns=[\"price\"])\n",
    "y = df_cleaned[\"price\"]\n",
    "\n",
    "# Encode categorical columns\n",
    "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define best models with tuned parameters\n",
    "best_xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6)\n",
    "best_lgbm = LGBMRegressor(n_estimators=200, learning_rate=0.1, num_leaves=100)\n",
    "\n",
    "# Train models\n",
    "best_xgb.fit(X_train_scaled, y_train)\n",
    "best_lgbm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = best_xgb.predict(X_test_scaled)\n",
    "y_pred_lgbm = best_lgbm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate_model(y_test, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"\\nğŸ”¹ Model: {model_name}\")\n",
    "    print(f\"âœ… MAE: {mae:.2f}\")\n",
    "    print(f\"âœ… MSE: {mse:.2f}\")\n",
    "    print(f\"âœ… RMSE: {rmse:.2f}\")\n",
    "    print(f\"âœ… RÂ² Score: {r2:.5f}\")\n",
    "\n",
    "evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n",
    "evaluate_model(y_test, y_pred_lgbm, \"LightGBM\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_xgb, \"best_xgb_model.pkl\")\n",
    "joblib.dump(best_lgbm, \"best_lgbm_model.pkl\")\n",
    "print(\"\\nâœ… Models saved successfully as 'best_xgb_model.pkl' and 'best_lgbm_model.pkl'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\Users\\dell\\miniconda3\\envs\\carp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 11797, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 17538.921166\n",
      "âœ… Models, encoders, and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#save scaller\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"cleaned_car_dataset.csv\"\n",
    "df_cleaned = pd.read_csv(file_path)\n",
    "\n",
    "# Split features and target\n",
    "X = df_cleaned.drop(columns=[\"price\"])\n",
    "y = df_cleaned[\"price\"]\n",
    "\n",
    "# Encode categorical columns and save encoders\n",
    "encoders = {}\n",
    "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    encoders[col] = le  # Store the encoder\n",
    "\n",
    "# Save encoders\n",
    "joblib.dump(encoders, \"label_encoders.pkl\")\n",
    "\n",
    "# Normalize numerical features and save scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models\n",
    "best_xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6)\n",
    "best_lgbm = LGBMRegressor(n_estimators=200, learning_rate=0.1, num_leaves=100)\n",
    "\n",
    "best_xgb.fit(X_train, y_train)\n",
    "best_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Save trained models\n",
    "joblib.dump(best_xgb, \"best_xgb_model.pkl\")\n",
    "joblib.dump(best_lgbm, \"best_lgbm_model.pkl\")\n",
    "\n",
    "print(\"âœ… Models, encoders, and scaler saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction script ready to use!\n"
     ]
    }
   ],
   "source": [
    "#save encoder\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved models\n",
    "best_xgb = joblib.load(\"best_xgb_model.pkl\")\n",
    "best_lgbm = joblib.load(\"best_lgbm_model.pkl\")\n",
    "\n",
    "# Load preprocessing objects\n",
    "encoders = joblib.load(\"label_encoders.pkl\")  # Load saved LabelEncoders\n",
    "scaler = joblib.load(\"scaler.pkl\")  # Load saved StandardScaler\n",
    "\n",
    "def preprocess_user_input(user_input):\n",
    "    \"\"\"Preprocess user input to match the trained model format.\"\"\"\n",
    "    user_df = pd.DataFrame([user_input])\n",
    "\n",
    "    # Encode categorical columns using saved encoders\n",
    "    categorical_cols = [\"make_model\", \"body_type\", \"Type\", \"Fuel\", \"Gearing_Type\", \"Drive_chain\", \"Paint_Type\", \"Upholstery_type\"]\n",
    "    for col in categorical_cols:\n",
    "        if col in user_df.columns and col in encoders:\n",
    "            user_df[col] = encoders[col].transform(user_df[col])\n",
    "\n",
    "    # Scale numerical features using saved scaler\n",
    "    numerical_cols = [\"km\", \"age\", \"Previous_Owners\", \"hp_kW\", \"Displacement_cc\", \"Weight_kg\", \"cons_comb\"]\n",
    "    user_df[numerical_cols] = scaler.transform(user_df[numerical_cols])\n",
    "\n",
    "    return user_df\n",
    "\n",
    "def predict_price(user_input):\n",
    "    \"\"\"Predicts car price based on user input.\"\"\"\n",
    "    user_df = preprocess_user_input(user_input)\n",
    "    predicted_price = best_xgb.predict(user_df)\n",
    "    return predicted_price[0]\n",
    "\n",
    "print(\"âœ… Prediction script ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Car Recommendation System** \n",
      "\n",
      "User Input: {'make_model': 'audi a1', 'min_mileage': 10000.0, 'max_mileage': 12000.0, 'budget': 250000.0, 'Fuel': 'diesel', 'body_type': 'sedans'}\n",
      "Filtered Cars Count: 5\n",
      "Filtered Cars Sample:\n",
      "     make_model       km    price  estimated_resale_price\n",
      "729     Audi A1  10500.0  22500.0                19125.00\n",
      "1661    Audi A1  11432.0  21660.0                18411.00\n",
      "1077    Audi A1  10775.0  19977.0                16980.45\n",
      "1020    Audi A1  10771.0  19950.0                16957.50\n",
      "1024    Audi A1  11380.0  19900.0                16915.00\n",
      "\n",
      " **Recommended Cars:**\n",
      "     make_model       km    price  estimated_resale_price\n",
      "729     Audi A1  10500.0  22500.0                19125.00\n",
      "1661    Audi A1  11432.0  21660.0                18411.00\n",
      "1077    Audi A1  10775.0  19977.0                16980.45\n",
      "1020    Audi A1  10771.0  19950.0                16957.50\n",
      "1024    Audi A1  11380.0  19900.0                16915.00\n"
     ]
    }
   ],
   "source": [
    "#script3\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load trained models\n",
    "best_xgb = joblib.load(\"best_xgb_model.pkl\")\n",
    "\n",
    "# Load preprocessing objects (LabelEncoders & Scaler)\n",
    "encoders = joblib.load(\"label_encoders.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv(\"cleaned_car_dataset.csv\")\n",
    "\n",
    "# Expected columns\n",
    "expected_numerical_cols = [\n",
    "    \"km\", \"age\", \"Previous_Owners\", \"hp_kW\", \"Displacement_cc\", \n",
    "    \"Weight_kg\", \"cons_comb\", \"estimated_resale_price\", \"price_per_km\", \"age_mileage_score\"\n",
    "]\n",
    "expected_categorical_cols = [\n",
    "    \"make_model\", \"body_type\", \"Type\", \"Fuel\", \"Gearing_Type\", \n",
    "    \"Drive_chain\", \"Paint_Type\", \"Upholstery_type\"\n",
    "]\n",
    "\n",
    "# Hints for user input\n",
    "car_models = [\"Audi A1\", \"Audi A2\", \"Audi A3\", \"Opel Astra\", \"Opel Corsa\", \"Opel Insignia\",\n",
    "              \"Renault Clio\", \"Renault Duster\", \"Renault Espace\"]\n",
    "fuel_types = [\"Diesel\", \"Benzine\", \"LPG/CNG\", \"Electric\"]\n",
    "body_types = [\"Sedans\", \"Station wagon\", \"Compact\", \"Coupe\", \"Van\", \"Off-Road\", \"Convertible\", \"Transporter\"]\n",
    "\n",
    "def preprocess_user_input(user_input):\n",
    "    \"\"\"Preprocess user input to match trained model format.\"\"\"\n",
    "    user_df = pd.DataFrame([user_input])\n",
    "\n",
    "    # Ensure missing numerical columns are filled with default values (0)\n",
    "    for col in expected_numerical_cols:\n",
    "        if col not in user_df:\n",
    "            user_df[col] = 0  \n",
    "\n",
    "    # Ensure missing categorical columns are filled with \"Unknown\"\n",
    "    for col in expected_categorical_cols:\n",
    "        if col not in user_df:\n",
    "            user_df[col] = \"Unknown\"\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    user_df = user_df[expected_numerical_cols + expected_categorical_cols]\n",
    "\n",
    "    # Encode categorical columns\n",
    "    for col in expected_categorical_cols:\n",
    "        if col in encoders:\n",
    "            le = encoders[col]\n",
    "            known_labels = set(le.classes_)\n",
    "            user_df[col] = user_df[col].apply(lambda x: le.transform([x])[0] if x in known_labels else -1)\n",
    "\n",
    "    # Convert categorical columns to numeric\n",
    "    user_df[expected_categorical_cols] = user_df[expected_categorical_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Fill NaN values\n",
    "    user_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Ensure numerical columns match the scaler\n",
    "    user_df[scaler.feature_names_in_] = scaler.transform(user_df[scaler.feature_names_in_])\n",
    "\n",
    "    return user_df\n",
    "\n",
    "def predict_price(user_input):\n",
    "    \"\"\"Predicts the price of a car based on user specifications.\"\"\"\n",
    "    user_df = preprocess_user_input(user_input)\n",
    "    predicted_price = best_xgb.predict(user_df)\n",
    "    return predicted_price[0]\n",
    "\n",
    "def recommend_cars(user_input, dataset):\n",
    "    \"\"\"Recommends cars based on user preferences.\"\"\"\n",
    "\n",
    "    # Ensure min_mileage is not greater than max_mileage\n",
    "    if user_input[\"min_mileage\"] > user_input[\"max_mileage\"]:\n",
    "        print(\"âš ï¸ Warning: Min mileage is greater than Max mileage. Swapping values.\")\n",
    "        user_input[\"min_mileage\"], user_input[\"max_mileage\"] = user_input[\"max_mileage\"], user_input[\"min_mileage\"]\n",
    "\n",
    "    # Normalize input case\n",
    "    user_input[\"make_model\"] = user_input[\"make_model\"].strip().title()\n",
    "    user_input[\"Fuel\"] = user_input[\"Fuel\"].strip().title()\n",
    "    user_input[\"body_type\"] = user_input[\"body_type\"].strip().title()\n",
    "\n",
    "    # Check if model exists in dataset\n",
    "    if user_input[\"make_model\"] not in dataset[\"make_model\"].unique():\n",
    "        print(f\"âš ï¸ Model '{user_input['make_model']}' not found. Showing closest matches.\")\n",
    "\n",
    "    # Filtering based on user input\n",
    "    filtered_cars = dataset[\n",
    "        (dataset[\"make_model\"].str.lower() == user_input[\"make_model\"].lower()) &\n",
    "        (dataset[\"km\"] >= user_input[\"min_mileage\"]) &\n",
    "        (dataset[\"km\"] <= user_input[\"max_mileage\"]) &\n",
    "        (dataset[\"price\"] <= user_input[\"budget\"]) &\n",
    "        (dataset[\"Fuel\"].str.lower().str.contains(user_input[\"Fuel\"].lower(), na=False)) &\n",
    "        (dataset[\"body_type\"].str.lower() == user_input[\"body_type\"].lower())\n",
    "    ]\n",
    "\n",
    "    # If no matches, expand search criteria\n",
    "    if filtered_cars.empty:\n",
    "        print(\"âš ï¸ No exact matches found. Expanding search criteria...\")\n",
    "        filtered_cars = dataset[\n",
    "            (dataset[\"km\"] <= user_input[\"max_mileage\"] * 1.5) &  # Allow 50% higher mileage\n",
    "            (dataset[\"price\"] <= user_input[\"budget\"] * 1.2)      # Increase budget flexibility\n",
    "        ]\n",
    "\n",
    "    # Sort results based on best resale value and price\n",
    "    filtered_cars = filtered_cars.sort_values(by=[\"estimated_resale_price\", \"price\"], ascending=[False, True])\n",
    "\n",
    "    return filtered_cars.head(5)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the car recommendation system.\"\"\"\n",
    "    dataset = pd.read_csv(\"cleaned_car_dataset.csv\")\n",
    "\n",
    "    print(\"\\n **Car Recommendation System** \\n\")\n",
    "    \n",
    "    user_input = {\n",
    "        \"make_model\": input(f\"Enter car model (e.g., {', '.join(car_models[:3])}, ...): \"),\n",
    "        \"min_mileage\": float(input(\"Enter min mileage (e.g., 20000): \") or 0),\n",
    "        \"max_mileage\": float(input(\"Enter max mileage (e.g., 60000): \") or float('inf')),\n",
    "        \"budget\": float(input(\"Enter budget (e.g., 25000): \") or float('inf')),\n",
    "        \"Fuel\": input(f\"Enter fuel type ({', '.join(fuel_types)}): \"),\n",
    "        \"body_type\": input(f\"Enter body type ({', '.join(body_types)}): \")\n",
    "    }\n",
    "\n",
    "    # Debugging: Check user input and filtering process\n",
    "    print(\"User Input:\", user_input)\n",
    "    \n",
    "    recommendations = recommend_cars(user_input, dataset)\n",
    "\n",
    "    print(\"Filtered Cars Count:\", len(recommendations))\n",
    "    print(\"Filtered Cars Sample:\")\n",
    "    print(recommendations[[\"make_model\", \"km\", \"price\", \"estimated_resale_price\"]].head())\n",
    "\n",
    "    # Print recommendations\n",
    "    if not recommendations.empty:\n",
    "        print(\"\\n **Recommended Cars:**\")\n",
    "        print(recommendations[[\"make_model\", \"km\", \"price\", \"estimated_resale_price\"]])\n",
    "    else:\n",
    "        print(\"\\n No cars found matching your criteria. Try adjusting your preferences.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
